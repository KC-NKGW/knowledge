自然言語処理

昨今はGPT-3やLaMDAなどの大規模言語モデルがよく話題になる。
確かに生成系のタスクであれば大規模言語モデルが必要になるかと思う。

ただし私がかかわってきた実務的なタスクでは基本的に生成ではない検索や分類、要約(意味抽出型)がほとんどである。
高度なアルゴリズムでもBERT、データ量等によってはtf-idf+ナイーブベイズというかなり古典的な手法の方が、処理時間を考えると有効な場合もある。
※もちろんベクトル化で言うとword2vecやfasttext、分類器で言うとLightGBMやSVMなど色々試すというのが前提である。

なお要約タスクには意味抽象型が最近かなりの精度で達成されているようだが、例えばアンケート結果の生データを読むという意味でも意味抽象型要約も無駄ではないと考えている。

タスクの目的次第でアルゴリズムは使い分ける必要がある。


